{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate rap song out of hate speach tweets\n",
    "\n",
    "Just for fun, much more could be done."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import nltk\n",
    "import random\n",
    "import io\n",
    "import re\n",
    "\n",
    "# Get hate speach tweets from URL as a dataframe\n",
    "url = 'https://raw.githubusercontent.com/t-davidson/hate-speech-and-offensive-language/master/data/labeled_data.csv'\n",
    "raw_content = requests.get(url).content\n",
    "formated_content = io.StringIO(raw_content.decode('utf-8'))\n",
    "df = pd.read_csv(formated_content).iloc[:,1:]\n",
    "\n",
    "\n",
    "# Clean tweets text\n",
    "def remove_mentions(text):\n",
    "    return ' '.join([w for w in text.split(' ') if not w.startswith('@')])\n",
    "def remove_hashtags(text):\n",
    "    return ' '.join([w for w in text.split(' ') if not w.startswith('#')])\n",
    "def remove_url(text):\n",
    "    return re.sub('https?://[A-Za-z0-9./]+','',text)\n",
    "def remove_special_characters(text):\n",
    "    return re.sub(\"[^a-zA-Z]\", \" \", text)\n",
    "def lowercase_text(text):\n",
    "    return text.lower()\n",
    "def strip_inner_spaces(text):\n",
    "    return ' '.join([w.strip() for w in text.split()])\n",
    "\n",
    "df['tweet'] = df.tweet.apply(remove_mentions)\n",
    "df['tweet'] = df.tweet.apply(remove_hashtags)\n",
    "df['tweet'] = df.tweet.apply(remove_url)\n",
    "df['tweet'] = df.tweet.apply(remove_special_characters)\n",
    "df['tweet'] = df.tweet.apply(lowercase_text)\n",
    "df['tweet'] = df.tweet.apply(strip_inner_spaces)\n",
    "\n",
    "\n",
    "# Get top 1000 common words\n",
    "all_words  = ' '.join(df.tweet.tolist()).split(' ')\n",
    "unique, counts = np.unique(all_words, return_counts=True)\n",
    "most_common = list(zip(unique, counts))\n",
    "most_common.sort(key=lambda x: x[1])\n",
    "top_words = most_common[::-1]\n",
    "most_common_1000 = [w[0] for w in top_words[:1000]]\n",
    "\n",
    "\n",
    "# Set rap generator\n",
    "BASE_TEXT = most_common_1000\n",
    "bigrams = nltk.bigrams(BASE_TEXT)\n",
    "cfd = nltk.ConditionalFreqDist(bigrams)\n",
    "\n",
    "def rap_line(poem_length):\n",
    "    word = random.choice(BASE_TEXT)\n",
    "    generated = []\n",
    "    for i in range(poem_length):\n",
    "        generated.append(word)\n",
    "        if word in cfd:\n",
    "            word = random.choice(list(cfd[word].keys()))\n",
    "        else:\n",
    "            break\n",
    "    return ' '.join(generated)\n",
    "\n",
    "def rap_song(poem_lines, poem_length):\n",
    "    for i in range(poem_lines):\n",
    "        print(rap_line(poem_length).title())\n",
    "        if i % 4 == 0:\n",
    "            print()\n",
    "    print('\\n\\n\\n ... i know i know. But still better than the mainstream!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shut Mean Fucked Night\n",
      "\n",
      "New Gonna Dat Him\n",
      "Wet Sometimes Pop Pics\n",
      "Homie Handle Gun Feeling\n",
      "As Go Fucking Yo\n",
      "\n",
      "Niggah Better Going Girls\n",
      "Clothes Bullshit Behind Walking\n",
      "Tonight Phone Kill Swear\n",
      "Actually Wow Win Thank\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " ... i know i know. But still better than the mainstream!\n"
     ]
    }
   ],
   "source": [
    "# Generate basic rap songs (still better than the mainstream!)\n",
    "\n",
    "poem_length = 4\n",
    "poem_lines  = 9 \n",
    "rap_song(poem_lines, poem_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There is 330923 words.\n",
      "There are 20437 unique words.\n",
      "\n",
      "i                9770\n",
      "a                9561\n",
      "bitch            8331\n",
      "rt               7647\n",
      "the              7213\n",
      "you              6808\n",
      "to               5343\n",
      "that             4038\n",
      "and              3991\n",
      "t                3896\n",
      "my               3592\n",
      "bitches          3111\n",
      "in               3067\n",
      "is               2920\n",
      "like             2787\n",
      "me               2761\n",
      "it               2685\n",
      "s                2652\n",
      "of               2552\n",
      "on               2538\n",
      "hoes             2394\n",
      "be               2382\n",
      "this             2165\n",
      "pussy            2153\n",
      "for              2128\n",
      "all              1952\n",
      "hoe              1949\n",
      "with             1854\n",
      "m                1691\n",
      "ass              1576\n",
      "your             1542\n",
      "up               1539\n",
      "if               1514\n",
      "don              1508\n",
      "they             1493\n",
      "but              1489\n",
      "just             1471\n",
      "get              1437\n",
      "fuck             1429\n",
      "so               1392\n",
      "can              1369\n",
      "she              1355\n",
      "no               1338\n",
      "when             1329\n",
      "these            1323\n",
      "u                1310\n",
      "got              1291\n",
      "shit             1288\n",
      "nigga            1228\n",
      "not              1183\n"
     ]
    }
   ],
   "source": [
    "# Some frequencies, data exploration, etc\n",
    "\n",
    "nr_words  = len(all_words)\n",
    "nr_unique = len(unique)\n",
    "print('There is {} words.'.format(nr_words))\n",
    "print('There are {} unique words.'.format(nr_unique))\n",
    "print()\n",
    "\n",
    "for w in top_words[:50]:\n",
    "    print('{:10} {:10}'.format(w[0],w[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
