{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(777, 19)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Private</th>\n",
       "      <th>Apps</th>\n",
       "      <th>Accept</th>\n",
       "      <th>Enroll</th>\n",
       "      <th>Top10perc</th>\n",
       "      <th>Top25perc</th>\n",
       "      <th>F.Undergrad</th>\n",
       "      <th>P.Undergrad</th>\n",
       "      <th>Outstate</th>\n",
       "      <th>Room.Board</th>\n",
       "      <th>Books</th>\n",
       "      <th>Personal</th>\n",
       "      <th>PhD</th>\n",
       "      <th>Terminal</th>\n",
       "      <th>S.F.Ratio</th>\n",
       "      <th>perc.alumni</th>\n",
       "      <th>Expend</th>\n",
       "      <th>Grad.Rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Abilene Christian University</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1660</td>\n",
       "      <td>1232</td>\n",
       "      <td>721</td>\n",
       "      <td>23</td>\n",
       "      <td>52</td>\n",
       "      <td>2885</td>\n",
       "      <td>537</td>\n",
       "      <td>7440</td>\n",
       "      <td>3300</td>\n",
       "      <td>450</td>\n",
       "      <td>2200</td>\n",
       "      <td>70</td>\n",
       "      <td>78</td>\n",
       "      <td>18.1</td>\n",
       "      <td>12</td>\n",
       "      <td>7041</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Unnamed: 0 Private  Apps  Accept  Enroll  Top10perc  \\\n",
       "0  Abilene Christian University     Yes  1660    1232     721         23   \n",
       "\n",
       "   Top25perc  F.Undergrad  P.Undergrad  Outstate  Room.Board  Books  Personal  \\\n",
       "0         52         2885          537      7440        3300    450      2200   \n",
       "\n",
       "   PhD  Terminal  S.F.Ratio  perc.alumni  Expend  Grad.Rate  \n",
       "0   70        78       18.1           12    7041         60  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import itertools\n",
    "df = pd.read_csv('College.csv', sep=',')\n",
    "\n",
    "print(df.shape)\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Yes    565\n",
       "No     212\n",
       "Name: Private, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Private.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predict collage: Private/Public"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Baseline: Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from sklearn.utils import shuffle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy - train: 0.9347\n",
      "Accuracy - test:  0.9436\n",
      "\n",
      "Confusion matrix:\n",
      "TP: 136   TN: 48\n",
      "FP: 5     FN: 6\n",
      "\n",
      "Classification report: \n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.91      0.90        53\n",
      "           1       0.96      0.96      0.96       142\n",
      "\n",
      "   micro avg       0.94      0.94      0.94       195\n",
      "   macro avg       0.93      0.93      0.93       195\n",
      "weighted avg       0.94      0.94      0.94       195\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/luke/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/data.py:323: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df = pd.read_csv('College.csv', sep=',')\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le =  LabelEncoder()\n",
    "y =  le.fit_transform(df.loc[ :, 'Private'])\n",
    "X =  df.iloc[ :,2:26]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "\n",
    "scaler = MinMaxScaler(feature_range = (0,1))\n",
    "scaler.fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "LGR = LogisticRegression(penalty='l2', \n",
    "                         dual=False, \n",
    "                         tol=0.0001, \n",
    "                         C=1.0, \n",
    "                         fit_intercept=True, \n",
    "                         intercept_scaling=1, \n",
    "                         class_weight=None, \n",
    "                         random_state=None, \n",
    "                         solver='lbfgs', \n",
    "                         max_iter=100, \n",
    "                         multi_class='warn', \n",
    "                         verbose=0, \n",
    "                         warm_start=False, \n",
    "                         n_jobs=None).fit(X_train, y_train)\n",
    "\n",
    "accuracy_train = round(LGR.score(X_train, y_train), 4)\n",
    "accuracy_test  = round(LGR.score(X_test,  y_test), 4)\n",
    "predictions = LGR.predict(X_test)\n",
    "probabilities = LGR.predict_proba(X_test)\n",
    "tn, fp, fn, tp  = confusion_matrix(y_test, predictions).ravel()\n",
    "\n",
    "print('Accuracy - train: {}'.format(accuracy_train))\n",
    "print('Accuracy - test:  {}'.format(accuracy_test))\n",
    "print('\\nConfusion matrix:\\nTP: {:<5} TN: {}\\nFP: {:<5} FN: {}'.format(tp, tn, fp, fn))\n",
    "print('\\nClassification report: \\n\\n', classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy - train: 0.943\n",
      "Accuracy - test:  0.9786\n",
      "\n",
      "Confusion matrix:\n",
      "TP: 136   TN: 47\n",
      "FP: 2     FN: 2\n",
      "\n",
      "Classification report: \n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.96      0.96        49\n",
      "           1       0.99      0.99      0.99       138\n",
      "\n",
      "   micro avg       0.98      0.98      0.98       187\n",
      "   macro avg       0.97      0.97      0.97       187\n",
      "weighted avg       0.98      0.98      0.98       187\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/luke/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/data.py:323: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n"
     ]
    }
   ],
   "source": [
    "def remove_outlier(df_in, col_name):\n",
    "    #print('Before', df_in[col_name].min(), df_in[col_name].max())\n",
    "    q1 = df_in[col_name].quantile(0.25)\n",
    "    q3 = df_in[col_name].quantile(0.75)\n",
    "    iqr = q3-q1 #Interquartile range\n",
    "    fence_low  = q1-6.4*iqr\n",
    "    fence_high = q3+6.4*iqr\n",
    "    #print(iqr,fence_low, fence_high)\n",
    "    df_out = df_in.loc[(df_in[col_name] > fence_low) & (df_in[col_name] < fence_high)]\n",
    "    #print('After', df_out[col_name].min(), df_out[col_name].max())\n",
    "    return df_out\n",
    "\n",
    "df = pd.read_csv('College.csv', sep=',')\n",
    "for column in df.columns[2:]:\n",
    "    df = remove_outlier(df, column)\n",
    "\n",
    "y =  le.fit_transform(df.loc[ :, 'Private'])\n",
    "X =  df.iloc[ :,2:] # (df.shape[1]-2)]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "\n",
    "scaler = MinMaxScaler(feature_range = (0,1))\n",
    "scaler.fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "LGR = LogisticRegression(penalty='l1', \n",
    "                         dual=False, \n",
    "                         tol=0.0001, \n",
    "                         C=1.6, \n",
    "                         fit_intercept=True, \n",
    "                         intercept_scaling=1, \n",
    "                         class_weight=None, \n",
    "                         random_state=None, \n",
    "                         solver='liblinear', \n",
    "                         max_iter=100, \n",
    "                         multi_class='warn', \n",
    "                         verbose=0, \n",
    "                         warm_start=False, \n",
    "                         n_jobs=None).fit(X_train, y_train)\n",
    "\n",
    "accuracy_train = round(LGR.score(X_train, y_train), 4)\n",
    "accuracy_test  = round(LGR.score(X_test,  y_test), 4)\n",
    "predictions = LGR.predict(X_test)\n",
    "probabilities = LGR.predict_proba(X_test)\n",
    "tn, fp, fn, tp  = confusion_matrix(y_test, predictions).ravel()\n",
    "\n",
    "print('Accuracy - train: {}'.format(accuracy_train))\n",
    "print('Accuracy - test:  {}'.format(accuracy_test))\n",
    "print('\\nConfusion matrix:\\nTP: {:<5} TN: {}\\nFP: {:<5} FN: {}'.format(tp, tn, fp, fn))\n",
    "print('\\nClassification report: \\n\\n', classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Balance datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Yes    555\n",
       "No     193\n",
       "Name: Private, dtype: int64"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Private.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dfb shape: (386, 19)\n",
      "Positives: 193\n",
      "Negatives: 193\n",
      "Sample cost: 362\n",
      "Accuracy - train: 0.9377\n",
      "Accuracy - test:  0.9175\n",
      "\n",
      "Confusion matrix:\n",
      "TP: 39    TN: 50\n",
      "FP: 3     FN: 5\n",
      "\n",
      "Classification report: \n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.94      0.93        53\n",
      "           1       0.93      0.89      0.91        44\n",
      "\n",
      "   micro avg       0.92      0.92      0.92        97\n",
      "   macro avg       0.92      0.91      0.92        97\n",
      "weighted avg       0.92      0.92      0.92        97\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/luke/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/data.py:323: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n"
     ]
    }
   ],
   "source": [
    "df.Private = le.fit_transform(df.Private)\n",
    "negative = df[df.Private == 0]\n",
    "positive = df[df.Private == 1].sample(len(negative))\n",
    "\n",
    "dfb = pd.concat([negative,positive]).reset_index(drop=True)\n",
    "#dfb =  add_features(dfb, 26)\n",
    "dfb =  shuffle(dfb)\n",
    "\n",
    "print('dfb shape:', dfb.shape)\n",
    "print('Positives:', len(positive))\n",
    "print('Negatives:', len(negative))\n",
    "print('Sample cost:', len(df)-len(dfb))   \n",
    "\n",
    "y =  dfb.loc[ :, 'Private']\n",
    "X =  dfb.iloc[ :,2:]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "\n",
    "scaler = MinMaxScaler(feature_range = (0,1))\n",
    "scaler.fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "LGR = LogisticRegression(penalty='l1', \n",
    "                         dual=False, \n",
    "                         tol=0.0001, \n",
    "                         C=1.6, \n",
    "                         fit_intercept=True, \n",
    "                         intercept_scaling=1, \n",
    "                         class_weight=None, \n",
    "                         random_state=None, \n",
    "                         solver='liblinear', \n",
    "                         max_iter=100, \n",
    "                         multi_class='warn', \n",
    "                         verbose=0, \n",
    "                         warm_start=False, \n",
    "                         n_jobs=None).fit(X_train, y_train)\n",
    "\n",
    "accuracy_train = round(LGR.score(X_train, y_train), 4)\n",
    "accuracy_test  = round(LGR.score(X_test,  y_test), 4)\n",
    "predictions = LGR.predict(X_test)\n",
    "probabilities = LGR.predict_proba(X_test)\n",
    "tn, fp, fn, tp  = confusion_matrix(y_test, predictions).ravel()\n",
    "\n",
    "print('Accuracy - train: {}'.format(accuracy_train))\n",
    "print('Accuracy - test:  {}'.format(accuracy_test))\n",
    "print('\\nConfusion matrix:\\nTP: {:<5} TN: {}\\nFP: {:<5} FN: {}'.format(tp, tn, fp, fn))\n",
    "print('\\nClassification report: \\n\\n', classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9484536082474226\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=1000, max_depth=10000).fit(X_train, y_train) \n",
    "\n",
    "print(clf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_fit_time [0.00135164 0.0026942  0.0010067  0.00174105 0.00114443 0.00145049\n",
      " 0.00134754 0.00149176]\n",
      "mean_score_time [0.00036571 0.00047414 0.00030594 0.00036912 0.00029843 0.00032694\n",
      " 0.00029528 0.00032623]\n",
      "mean_test_score [0.89273356 0.90311419 0.9100346  0.89965398 0.9100346  0.9100346\n",
      " 0.91349481 0.92387543]\n",
      "mean_train_score [0.90309991 0.90118712 0.91849202 0.91809999 0.93194772 0.93156309\n",
      " 0.93502023 0.94693896]\n",
      "param_C [0.1 0.1 1 1 10 10 20 20]\n",
      "param_kernel ['linear' 'rbf' 'linear' 'rbf' 'linear' 'rbf' 'linear' 'rbf']\n",
      "params [{'C': 0.1, 'kernel': 'linear'}, {'C': 0.1, 'kernel': 'rbf'}, {'C': 1, 'kernel': 'linear'}, {'C': 1, 'kernel': 'rbf'}, {'C': 10, 'kernel': 'linear'}, {'C': 10, 'kernel': 'rbf'}, {'C': 20, 'kernel': 'linear'}, {'C': 20, 'kernel': 'rbf'}]\n",
      "rank_test_score [8 6 3 7 3 3 2 1]\n",
      "split0_test_score [0.83333333 0.86666667 0.9        0.86666667 0.86666667 0.86666667\n",
      " 0.9        0.9       ]\n",
      "split0_train_score [0.9034749  0.8957529  0.91891892 0.90733591 0.93050193 0.92664093\n",
      " 0.93436293 0.94594595]\n",
      "split1_test_score [0.96666667 0.96666667 0.96666667 0.96666667 0.96666667 0.96666667\n",
      " 0.96666667 0.96666667]\n",
      "split1_train_score [0.8957529  0.8957529  0.92277992 0.91891892 0.93050193 0.93050193\n",
      " 0.93050193 0.94208494]\n",
      "split2_test_score [0.89655172 0.93103448 0.96551724 0.93103448 0.86206897 0.86206897\n",
      " 0.86206897 0.93103448]\n",
      "split2_train_score [0.90384615 0.9        0.91153846 0.91923077 0.93846154 0.93846154\n",
      " 0.94615385 0.95      ]\n",
      "split3_test_score [0.89655172 0.86206897 0.89655172 0.89655172 0.93103448 0.93103448\n",
      " 0.93103448 0.93103448]\n",
      "split3_train_score [0.90384615 0.91153846 0.91153846 0.91923077 0.93846154 0.93846154\n",
      " 0.93461538 0.95      ]\n",
      "split4_test_score [0.96551724 0.96551724 0.96551724 0.96551724 0.96551724 0.96551724\n",
      " 0.96551724 0.96551724]\n",
      "split4_train_score [0.89615385 0.89230769 0.91153846 0.91923077 0.93076923 0.92307692\n",
      " 0.93076923 0.93461538]\n",
      "split5_test_score [0.93103448 0.93103448 0.93103448 0.93103448 0.96551724 0.96551724\n",
      " 0.96551724 1.        ]\n",
      "split5_train_score [0.89230769 0.90384615 0.91923077 0.91538462 0.92307692 0.93076923\n",
      " 0.92692308 0.95      ]\n",
      "split6_test_score [0.89655172 0.89655172 0.89655172 0.89655172 0.89655172 0.89655172\n",
      " 0.89655172 0.89655172]\n",
      "split6_train_score [0.89615385 0.90769231 0.92692308 0.91538462 0.93076923 0.93461538\n",
      " 0.93461538 0.95      ]\n",
      "split7_test_score [0.85714286 0.89285714 0.89285714 0.89285714 0.92857143 0.92857143\n",
      " 0.92857143 0.92857143]\n",
      "split7_train_score [0.91187739 0.90038314 0.91570881 0.91570881 0.92720307 0.91954023\n",
      " 0.93103448 0.94636015]\n",
      "split8_test_score [0.78571429 0.82142857 0.75       0.75       0.78571429 0.78571429\n",
      " 0.78571429 0.78571429]\n",
      "split8_train_score [0.91954023 0.91187739 0.93103448 0.93103448 0.94252874 0.94252874\n",
      " 0.95019157 0.95402299]\n",
      "split9_test_score [0.89285714 0.89285714 0.92857143 0.89285714 0.92857143 0.92857143\n",
      " 0.92857143 0.92857143]\n",
      "split9_train_score [0.90804598 0.89272031 0.91570881 0.91954023 0.92720307 0.93103448\n",
      " 0.93103448 0.94636015]\n",
      "std_fit_time [1.36203374e-04 1.01798873e-04 1.49125818e-05 2.72051589e-04\n",
      " 7.54863833e-05 5.02104999e-05 2.02421109e-04 8.23061856e-05]\n",
      "std_score_time [4.82437447e-05 4.06648800e-05 7.64487603e-06 1.11133751e-05\n",
      " 1.53186674e-05 9.68874555e-06 1.46557628e-05 1.51811240e-05]\n",
      "std_test_score [0.05337816 0.04409772 0.05987602 0.05824788 0.05480258 0.05480258\n",
      " 0.05297704 0.05425529]\n",
      "std_train_score [0.00799995 0.006946   0.00638795 0.00556967 0.00572268 0.00683788\n",
      " 0.00700506 0.0051454 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/luke/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n",
      "/home/luke/anaconda3/lib/python3.6/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('mean_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/home/luke/anaconda3/lib/python3.6/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split0_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/home/luke/anaconda3/lib/python3.6/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split1_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/home/luke/anaconda3/lib/python3.6/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split2_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/home/luke/anaconda3/lib/python3.6/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split3_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/home/luke/anaconda3/lib/python3.6/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split4_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/home/luke/anaconda3/lib/python3.6/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split5_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/home/luke/anaconda3/lib/python3.6/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split6_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/home/luke/anaconda3/lib/python3.6/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split7_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/home/luke/anaconda3/lib/python3.6/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split8_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/home/luke/anaconda3/lib/python3.6/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split9_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/home/luke/anaconda3/lib/python3.6/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('std_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm, datasets\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "svc = svm.SVC(gamma=\"scale\")\n",
    "parameters = {'kernel':('linear', 'rbf'), 'C':[0.1, 1, 10, 20]}\n",
    "clf = GridSearchCV(svc, parameters, cv=10)\n",
    "clf.fit(X_train, y_train) \n",
    "\n",
    "for result in sorted(clf.cv_results_.keys()):\n",
    "    print(result, clf.cv_results_[result])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_fit_time [0.00114388 0.00155058 0.00110254 0.00141602]\n",
      "mean_score_time [0.00037847 0.00050011 0.00035315 0.0004096 ]\n",
      "mean_test_score [0.89965398 0.9100346  0.91349481 0.92387543]\n",
      "mean_train_score [0.91954273 0.91176912 0.9334033  0.93509745]\n",
      "param_C [1 1 10 10]\n",
      "param_kernel ['linear' 'rbf' 'linear' 'rbf']\n",
      "params [{'C': 1, 'kernel': 'linear'}, {'C': 1, 'kernel': 'rbf'}, {'C': 10, 'kernel': 'linear'}, {'C': 10, 'kernel': 'rbf'}]\n",
      "rank_test_score [4 3 2 1]\n",
      "split0_test_score [0.93220339 0.94915254 0.93220339 0.93220339]\n",
      "split0_train_score [0.91304348 0.90869565 0.92608696 0.92173913]\n",
      "split1_test_score [0.88135593 0.88135593 0.89830508 0.93220339]\n",
      "split1_train_score [0.92173913 0.9173913  0.94782609 0.93478261]\n",
      "split2_test_score [0.94736842 0.94736842 0.96491228 0.96491228]\n",
      "split2_train_score [0.9137931  0.90086207 0.91810345 0.93534483]\n",
      "split3_test_score [0.9122807  0.9122807  0.9122807  0.92982456]\n",
      "split3_train_score [0.91810345 0.9137931  0.92241379 0.93965517]\n",
      "split4_test_score [0.8245614  0.85964912 0.85964912 0.85964912]\n",
      "split4_train_score [0.93103448 0.91810345 0.95258621 0.94396552]\n",
      "std_fit_time [2.42524526e-04 5.46642591e-05 1.35527875e-04 1.92186163e-04]\n",
      "std_score_time [2.50271833e-05 6.90500050e-05 2.36423730e-05 2.31671224e-05]\n",
      "std_test_score [0.04332773 0.03545301 0.03481564 0.03436606]\n",
      "std_train_score [0.00654606 0.00639123 0.01403128 0.00745682]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/luke/anaconda3/lib/python3.6/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('mean_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/home/luke/anaconda3/lib/python3.6/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split0_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/home/luke/anaconda3/lib/python3.6/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split1_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/home/luke/anaconda3/lib/python3.6/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split2_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/home/luke/anaconda3/lib/python3.6/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split3_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/home/luke/anaconda3/lib/python3.6/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('split4_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "/home/luke/anaconda3/lib/python3.6/site-packages/sklearn/utils/deprecation.py:125: FutureWarning: You are accessing a training score ('std_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm, datasets\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "parameters = {'kernel':('linear', 'rbf'), 'C':[1, 10]}\n",
    "svc = svm.SVC(gamma=\"scale\")\n",
    "clf = GridSearchCV(svc, parameters, cv=5)\n",
    "clf.fit(X_train, y_train) \n",
    "clf.score(X_test, y_test) \n",
    "for result in sorted(clf.cv_results_.keys()):\n",
    "    print(result, clf.cv_results_[result])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([0.00114388, 0.00155058, 0.00110254, 0.00141602]),\n",
       " 'std_fit_time': array([2.42524526e-04, 5.46642591e-05, 1.35527875e-04, 1.92186163e-04]),\n",
       " 'mean_score_time': array([0.00037847, 0.00050011, 0.00035315, 0.0004096 ]),\n",
       " 'std_score_time': array([2.50271833e-05, 6.90500050e-05, 2.36423730e-05, 2.31671224e-05]),\n",
       " 'param_C': masked_array(data=[1, 1, 10, 10],\n",
       "              mask=[False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_kernel': masked_array(data=['linear', 'rbf', 'linear', 'rbf'],\n",
       "              mask=[False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'C': 1, 'kernel': 'linear'},\n",
       "  {'C': 1, 'kernel': 'rbf'},\n",
       "  {'C': 10, 'kernel': 'linear'},\n",
       "  {'C': 10, 'kernel': 'rbf'}],\n",
       " 'split0_test_score': array([0.93220339, 0.94915254, 0.93220339, 0.93220339]),\n",
       " 'split1_test_score': array([0.88135593, 0.88135593, 0.89830508, 0.93220339]),\n",
       " 'split2_test_score': array([0.94736842, 0.94736842, 0.96491228, 0.96491228]),\n",
       " 'split3_test_score': array([0.9122807 , 0.9122807 , 0.9122807 , 0.92982456]),\n",
       " 'split4_test_score': array([0.8245614 , 0.85964912, 0.85964912, 0.85964912]),\n",
       " 'mean_test_score': array([0.89965398, 0.9100346 , 0.91349481, 0.92387543]),\n",
       " 'std_test_score': array([0.04332773, 0.03545301, 0.03481564, 0.03436606]),\n",
       " 'rank_test_score': array([4, 3, 2, 1], dtype=int32),\n",
       " 'split0_train_score': array([0.91304348, 0.90869565, 0.92608696, 0.92173913]),\n",
       " 'split1_train_score': array([0.92173913, 0.9173913 , 0.94782609, 0.93478261]),\n",
       " 'split2_train_score': array([0.9137931 , 0.90086207, 0.91810345, 0.93534483]),\n",
       " 'split3_train_score': array([0.91810345, 0.9137931 , 0.92241379, 0.93965517]),\n",
       " 'split4_train_score': array([0.93103448, 0.91810345, 0.95258621, 0.94396552]),\n",
       " 'mean_train_score': array([0.91954273, 0.91176912, 0.9334033 , 0.93509745]),\n",
       " 'std_train_score': array([0.00654606, 0.00639123, 0.01403128, 0.00745682])}"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=10, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_estimator_ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
